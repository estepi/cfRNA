---
title: "Analysis of Maternal plasma cell-free RNA sequencing for preeclamptic and normotensive mothers"
author: "Estefania Mancini"
date: "2022-10-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```

# Data description

Liquid biopsies that measure circulating cell-free RNA (cfRNA) offer an unprecedented opportunity to noninvasively study the development of pregnancy-related complications and to bridge gaps in clinical care. Here, we sequenced cfRNA from 404 blood plasma samples (199 pregnant mothers) to identify and validate cfRNA transcriptomic changes that are associated with preeclampsia (PE), a multi-organ syndrome which is the second largest cause of maternal death globally. For each individual, samples were collected at one or more timepoints across gestation. For some, samples were also collected at least once post-partum

```{r readTable, eval=TRUE}
sra<- read.csv("SraRunTable.txt")
sra[1:5,1:5]
colnames(sra)
dim(sra)

```

## Some categorical variables


```{r descCat, eval=TRUE}

data <- data.frame(table(sra$Age))
head(data)

dataSex<-data.frame(table(sra$sex))
head(dataSex)

table(sra$Tissue)

dataDisease<-data.frame(table(sra$disease))
head(dataDisease)

```


# Download data

To retrieve the data from SRA to our instance in AWS, there are some options

## Classical approach: using sratoolkit

source: https://github.com/ncbi/sra-tools



```{bash getsratoolkit, eval=FALSE}

wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz
 tar -zxf sratoolkit.current-centos_linux64.tar.gz 

export PATH=$PATH:$PWD/sratoolkit.3.0.0-centos_linux64/bin
```

### Configure vdb
```{bash configure, eval=FALSE}
vdb-config --interactive
```

Source: https://github.com/ncbi/sra-tools/wiki/05.-Toolkit-Configuration

### Test

```{bash dump1, eval=FALSE}
fastq-dump --stdout -X 2 SRR390728
```

### Option more efficient:

Launch using tmux:

```{bash tmux, eval=FALSE}
tmux
```

```{bash fetch, eval=FALSE}

prefetch SRR17332994
```

1 sample: 1 minute

```{bash dump2, eval=FALSE}

fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip SRR17332994 &

```




## Accessing SRA Data in AWS

* https://www.ncbi.nlm.nih.gov/sra/docs/sra-aws-download/ 
* https://s3.console.aws.amazon.com/s3/buckets/sra-pub-src-2/?region=us-east-1&tab=objects

To download files from the AWS Console  using a browser, visit the HTTPS URL for the Coronaviridae dataset, Public SRA data, or Public user-submitted files respectively:

* https://s3.console.aws.amazon.com/s3/buckets/sra-pub-sars-cov2/
* https://s3.console.aws.amazon.com/s3/buckets/sra-pub-run-odp/
* https://s3.console.aws.amazon.com/s3/buckets/sra-pub-src-2/

From there you can navigate the directory structure using the provided graphical interface and you can search a given directory for your accession of interest using the provided search box near the top of the page. Once you have navigated to a specific file of interest you can click the Object URL link or use the Object actions button to copy the file to your own S3 bucket or download a copy to local storage.

To access files from within AWS, e.g. from an EC2 instance, you can use the AWS CLI  to perform an S3 copy or sync, using a command like this:


These data can also be accessed using various other tools and libraries. Access to files in the AWS Registry of Open Data is free. This is true whether you use the HTTPS or S3 URL. For S3 URLs, the transfer is free even if it crosses an AWS region boundary; there is no inter-regional data transfer fee.

If you don't know the Run accessions you are interested in, you can start by searching in the SRA Run Selector,
AWS Athena, or SRA Entrez.


## Copying from SRA S3 Bucket

### Already created instance:
![config](/Users/estepi/Documents/aws/config.png)


```{bash cps3, eval=FALSE}
aws s3 ls s3://sra-pub-sars-cov2/

aws s3 cp s3://sra-pub-sars-cov2/README.txt

aws s3 ls s3://sra-pub-run-odp/sra/SRR17333143/SRR17333143
```
Could not connect to the endpoint URL: "https://sra-pub-run-odp.s3.EU.amazonaws.com/?list-type=2&delimiter=%2F&prefix=sra%2FSRR17333143%2FSRR17333143&encoding-type=url"


![error1](/Users/estepi/Documents/aws/output.png)

##  New instance

- Configure the IAM Instance Profile to "AccesoS3" before launching

```{bash cps4, eval=FALSE}
aws s3 ls s3://sra-pub-sars-cov2/

aws s3 cp s3://sra-pub-sars-cov2/README.txt

aws s3 ls s3://sra-pub-run-odp/sra/SRR17333143/SRR17333143
```

![new](/Users/estepi/Documents/aws/new.png)



```{bash cps5, eval=FALSE}
aws s3 cp s3://sra-pub-run-odp/sra/SRR17332994/SRR17332994 .
```
download: s3://sra-pub-run-odp/sra/SRR17332994/SRR17332994 to ./SRR17332994
~ 1 minute


Then, we prepare extract files:

```{bash dump, eval=FALSE}
fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip SRR17332994 &
```

Using prefetch:

```{bash fetch2, eval=FALSE}

prefetch SRR17332994

fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip SRR17332994 &

```


* fastq-dump spends ~50 minutes for conversion

## What next?
Which is the best strategy for proccessing  ~400 samples